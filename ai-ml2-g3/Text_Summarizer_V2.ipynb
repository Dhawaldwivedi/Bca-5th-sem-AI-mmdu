{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN4irJzXvZA7bzShVt1ZQMq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dhawaldwivedi/Bca-5th-sem-AI-mmdu/blob/main/ai-ml2-g3/Text_Summarizer_V2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bNlvJurgCWys",
        "outputId": "2a8aceb0-e7a2-4f18-c71b-7e94939d1581"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "You are an expert teaching assistant specializing in Generative AI (GenAI). Your task is to generate a summary of a given paragraph, intended for training or evaluating a Recurrent Neural Network (RNN) based Sequence-to-Sequence (Seq2Seq) model. The summary should serve as a clear and concise representation of the original paragraph's meaning, suitable for students new to GenAI.\n",
            "The summary must meet the following criteria:\n",
            "Content Coverage: Comprehensively cover all essential topics presented in the original paragraph. Ensure it is self-contained and easily understandable for beginners in GenAI.\n",
            "Length Constraint: The summary's length should be approximately 40% of the original paragraph's length.\n",
            "Formatting: Use Markdown for formatting. Emphasize important keywords by using bold text. Format the summary's title as a level 1 heading (e.g., # Seq2Seq Based RNN).\n",
            "Scope Limitation: Strictly avoid introducing any information or concepts not explicitly mentioned in the original paragraph.\n",
            "Evaluation Focus: The summary will be evaluated based on its beginner-friendliness, accuracy in representing the original content, and overall fluency\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Assuming the uploaded file is named \"prompt.md\"\n",
        "filename = \"prompt.md\"\n",
        "\n",
        "# Read the contents\n",
        "with open(filename, \"r\") as file:\n",
        "    prompt_content = file.read()\n",
        "\n",
        "# Display content\n",
        "print(prompt_content)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming the uploaded file is named \"prompt.md\"\n",
        "filename2 = \"transcript.md\"\n",
        "\n",
        "# Read the contents\n",
        "with open(filename2, \"r\") as file:\n",
        "    transcript_content = file.read()\n",
        "\n",
        "# Display content\n",
        "print(transcript_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VlBDRnd6Cd3h",
        "outputId": "cfe71a8e-1e67-4b60-c1d1-5097c006a4b1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "What are RNN-based Seq2Seq Models?\n",
            "Hello everyone and Good day to all.\n",
            "In our last session, we introduced the general concept of Sequence-to-Sequence models, consisting of an encoder and a decoder. Historically, and for a long time, Recurrent Neural Networks, or RNNs, particularly LSTMs and GRUs, were the go-to choice for building these Sequence-to-Sequence components. Let's delve into how a Sequence-to-Sequence model works when powered by RNNs.\n",
            "As a recap, recall that RNNs are designed to process sequences by maintaining a hidden state that is updated at each step, incorporating information from the current input and the previous hidden state. This makes them naturally suited for handling sequential data like text.\n",
            "In a Sequence-to-Sequence model with RNNs, the Encoder is typically a multi-layer LSTM network. It reads the input sequence word by word (or token by token). At each time step, the encoder processes the current input token and the hidden state from the previous step to update its internal state. After processing the entire input sequence, ONLY the final hidden state of the encoder is taken as the fixed-size context vector representing the input sentence.\n",
            "Remember, this context vector is the numerical representation of the input sequence. \n",
            " \n",
            "It is then passed to the Decoder. The Decoder is another RNN (usually also an LSTM). It takes this context vector as its initial hidden state. The decoder's task is to generate the output sequence, one token at a time.\n",
            " \n",
            "While this RNN-based architecture was a breakthrough for NMT and other sequence tasks, it has significant drawbacks. The primary issue is the fixed-size context vector. For short sentences, this might be sufficient. But for longer sentences, forcing the encoder to compress all the information into a single vector creates an information bottleneck. The decoder has to rely solely on this single vector, which might not retain all the necessary details, especially those from the beginning of the input sequence. This often leads to performance degradation on longer sequences.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge both files using an f-string\n",
        "merged_output = f\"\"\"# Merged Prompt and Transcript\n",
        "\n",
        "## Prompt\n",
        "{prompt_content}\n",
        "\n",
        "---\n",
        "\n",
        "## Transcript\n",
        "{transcript_content}\n",
        "\"\"\"\n",
        "\n",
        "# Print the final formatted content\n",
        "print(merged_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4s1rpBNIlEQ",
        "outputId": "f2e1ca7e-f5d0-4a09-d3a7-51932236c890"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Merged Prompt and Transcript\n",
            "\n",
            "## Prompt\n",
            "\n",
            "You are an expert teaching assistant specializing in Generative AI (GenAI). Your task is to generate a summary of a given paragraph, intended for training or evaluating a Recurrent Neural Network (RNN) based Sequence-to-Sequence (Seq2Seq) model. The summary should serve as a clear and concise representation of the original paragraph's meaning, suitable for students new to GenAI.\n",
            "The summary must meet the following criteria:\n",
            "Content Coverage: Comprehensively cover all essential topics presented in the original paragraph. Ensure it is self-contained and easily understandable for beginners in GenAI.\n",
            "Length Constraint: The summary's length should be approximately 40% of the original paragraph's length.\n",
            "Formatting: Use Markdown for formatting. Emphasize important keywords by using bold text. Format the summary's title as a level 1 heading (e.g., # Seq2Seq Based RNN).\n",
            "Scope Limitation: Strictly avoid introducing any information or concepts not explicitly mentioned in the original paragraph.\n",
            "Evaluation Focus: The summary will be evaluated based on its beginner-friendliness, accuracy in representing the original content, and overall fluency\n",
            "\n",
            "\n",
            "---\n",
            "\n",
            "## Transcript\n",
            "\n",
            "What are RNN-based Seq2Seq Models?\n",
            "Hello everyone and Good day to all.\n",
            "In our last session, we introduced the general concept of Sequence-to-Sequence models, consisting of an encoder and a decoder. Historically, and for a long time, Recurrent Neural Networks, or RNNs, particularly LSTMs and GRUs, were the go-to choice for building these Sequence-to-Sequence components. Let's delve into how a Sequence-to-Sequence model works when powered by RNNs.\n",
            "As a recap, recall that RNNs are designed to process sequences by maintaining a hidden state that is updated at each step, incorporating information from the current input and the previous hidden state. This makes them naturally suited for handling sequential data like text.\n",
            "In a Sequence-to-Sequence model with RNNs, the Encoder is typically a multi-layer LSTM network. It reads the input sequence word by word (or token by token). At each time step, the encoder processes the current input token and the hidden state from the previous step to update its internal state. After processing the entire input sequence, ONLY the final hidden state of the encoder is taken as the fixed-size context vector representing the input sentence.\n",
            "Remember, this context vector is the numerical representation of the input sequence. \n",
            " \n",
            "It is then passed to the Decoder. The Decoder is another RNN (usually also an LSTM). It takes this context vector as its initial hidden state. The decoder's task is to generate the output sequence, one token at a time.\n",
            " \n",
            "While this RNN-based architecture was a breakthrough for NMT and other sequence tasks, it has significant drawbacks. The primary issue is the fixed-size context vector. For short sentences, this might be sufficient. But for longer sentences, forcing the encoder to compress all the information into a single vector creates an information bottleneck. The decoder has to rely solely on this single vector, which might not retain all the necessary details, especially those from the beginning of the input sequence. This often leads to performance degradation on longer sequences.\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "import os"
      ],
      "metadata": {
        "id": "sfJcDl8XJkoK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "# Get the API key from Colab secrets\n",
        "api_key = userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "# Configure Gemini SDK\n",
        "genai.configure(api_key=api_key)"
      ],
      "metadata": {
        "id": "tcVaJd_DJp5f"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the Gemini 2.5 Flash Lite preview model\n",
        "model = genai.GenerativeModel(\"gemini-2.5-flash-lite-preview-06-17\")"
      ],
      "metadata": {
        "id": "-gO1i-kkJuum"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(merged_output)\n",
        "\n",
        "# Print the result\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "vBRHmTLOJy_H",
        "outputId": "f3204cbd-eab8-45c2-b347-dbc1f68346ee"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# RNN-Based Seq2Seq Models\n",
            "\n",
            "**Recurrent Neural Networks (RNNs)**, including **LSTMs** and **GRUs**, were traditionally used to build **Sequence-to-Sequence (Seq2Seq)** models. These models consist of an **encoder** and a **decoder**.\n",
            "\n",
            "The **encoder**, often a multi-layer **LSTM**, processes the input sequence word by word. It uses a **hidden state** that updates with each input and the previous state, making it suitable for sequential data. After reading the entire input, only the encoder's **final hidden state** is used as a fixed-size **context vector**, which is a numerical representation of the input.\n",
            "\n",
            "This **context vector** is then passed to the **decoder**, another **RNN** (typically an **LSTM**). The decoder uses the context vector as its initial **hidden state** to generate the output sequence one token at a time.\n",
            "\n",
            "A major drawback of this **RNN-based Seq2Seq** architecture is the **fixed-size context vector**. For long input sequences, compressing all information into this single vector can lead to an **information bottleneck**, causing the decoder to lose details from the beginning of the input and reducing performance.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***hey***"
      ],
      "metadata": {
        "id": "lfBHDKicWZXQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Hi***"
      ],
      "metadata": {
        "id": "GbLN3UklcfGO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the response text as a markdown file\n",
        "output_file_name = \"summary1.md\"\n",
        "\n",
        "try:\n",
        "    with open(output_file_name, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(response.text)\n",
        "    print(f\"Successfully saved the summary to '{output_file_name}'.\")\n",
        "except IOError as e:\n",
        "    print(f\"Error saving the summary to '{output_file_name}': {e}\")"
      ],
      "metadata": {
        "id": "0KM3XHb2J3nX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fc58fbf-fd91-4b56-ec24-3461c1dcde9d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully saved the summary to 'summary1.md'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***hello***"
      ],
      "metadata": {
        "id": "EOl_XWBb6G6n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(response.text)"
      ],
      "metadata": {
        "id": "wwACVJGpKMxo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7312effa-212b-4979-8be7-de0486df0e6b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1148"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(transcript_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7lj6AfGCJwq",
        "outputId": "55ae8ed4-ddbc-46df-9327-d1796ad5d65a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2074"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(response.text)/len(transcript_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kst2HhS2CZ-5",
        "outputId": "6c248396-d6a3-45b7-f208-dcaea93ac58c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.553519768563163"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "uJJCW74Z2nLe"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FuS3d9xRTpD8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}